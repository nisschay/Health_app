{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "from google.colab import drive, files\n",
        "from google.colab import userdata\n",
        "!pip install PyPDF2 # Ensure PyPDF2 is installed\n",
        "import PyPDF2\n",
        "import io\n",
        "import re\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXXlpDvVZAFe",
        "outputId": "8447943e-e1e3-4404-83c2-2eb36015aaae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration for Standardization ---\n",
        "# You can expand these mappings as needed\n",
        "TEST_NAME_MAPPING = {\n",
        "    # Hematology\n",
        "    re.compile(r'haemoglobin', re.IGNORECASE): 'Haemoglobin',\n",
        "    re.compile(r'hgb', re.IGNORECASE): 'Haemoglobin',\n",
        "    re.compile(r'total leucocyte count', re.IGNORECASE): 'Total Leucocyte Count',\n",
        "    re.compile(r'tlc', re.IGNORECASE): 'Total Leucocyte Count',\n",
        "    re.compile(r'white blood cell count', re.IGNORECASE): 'Total Leucocyte Count',\n",
        "    re.compile(r'wbc', re.IGNORECASE): 'Total Leucocyte Count',\n",
        "    re.compile(r'platelet count', re.IGNORECASE): 'Platelet Count',\n",
        "    re.compile(r'rbc count', re.IGNORECASE): 'Red Blood Cell Count',\n",
        "    re.compile(r'red cell count', re.IGNORECASE): 'Red Blood Cell Count',\n",
        "    re.compile(r'hematocrit', re.IGNORECASE): 'Hematocrit',\n",
        "    re.compile(r'hct', re.IGNORECASE): 'Hematocrit',\n",
        "    re.compile(r'packed cell volume', re.IGNORECASE): 'Hematocrit',\n",
        "    re.compile(r'pcv', re.IGNORECASE): 'Hematocrit',\n",
        "    re.compile(r'mcv', re.IGNORECASE): 'Mean Corpuscular Volume (MCV)',\n",
        "    re.compile(r'mch', re.IGNORECASE): 'Mean Corpuscular Haemoglobin (MCH)',\n",
        "    re.compile(r'mchc', re.IGNORECASE): 'Mean Corpuscular Haemoglobin Concentration (MCHC)',\n",
        "    re.compile(r'rdw-cv', re.IGNORECASE): 'Red Cell Distribution Width - CV (RDW-CV)',\n",
        "    re.compile(r'rdw-sd', re.IGNORECASE): 'Red Cell Distribution Width - SD (RDW-SD)',\n",
        "    re.compile(r'neutrophils?', re.IGNORECASE): 'Neutrophils', # Matches Neutrophil and Neutrophils\n",
        "    re.compile(r'lymphocytes?', re.IGNORECASE): 'Lymphocytes',\n",
        "    re.compile(r'monocytes?', re.IGNORECASE): 'Monocytes',\n",
        "    re.compile(r'eosinophils?', re.IGNORECASE): 'Eosinophils',\n",
        "    re.compile(r'basophils?', re.IGNORECASE): 'Basophils',\n",
        "    re.compile(r'esr', re.IGNORECASE): 'Erythrocyte Sedimentation Rate (ESR)',\n",
        "    # Liver Function\n",
        "    re.compile(r'total bilirubin', re.IGNORECASE): 'Bilirubin - Total',\n",
        "    re.compile(r'direct bilirubin', re.IGNORECASE): 'Bilirubin - Direct',\n",
        "    re.compile(r'indirect bilirubin', re.IGNORECASE): 'Bilirubin - Indirect',\n",
        "    re.compile(r'sgpt', re.IGNORECASE): 'Alanine Aminotransferase (SGPT/ALT)',\n",
        "    re.compile(r'alt', re.IGNORECASE): 'Alanine Aminotransferase (SGPT/ALT)',\n",
        "    re.compile(r'sgot', re.IGNORECASE): 'Aspartate Aminotransferase (SGOT/AST)',\n",
        "    re.compile(r'ast', re.IGNORECASE): 'Aspartate Aminotransferase (SGOT/AST)',\n",
        "    re.compile(r'alkaline phosphatase', re.IGNORECASE): 'Alkaline Phosphatase (ALP)',\n",
        "    re.compile(r'alp', re.IGNORECASE): 'Alkaline Phosphatase (ALP)',\n",
        "    re.compile(r'total protein', re.IGNORECASE): 'Protein - Total',\n",
        "    re.compile(r'albumin', re.IGNORECASE): 'Albumin',\n",
        "    re.compile(r'globulin', re.IGNORECASE): 'Globulin',\n",
        "    re.compile(r'a/g ratio', re.IGNORECASE): 'Albumin/Globulin Ratio (A/G Ratio)',\n",
        "    # Kidney Function\n",
        "    re.compile(r'urea', re.IGNORECASE): 'Urea',\n",
        "    re.compile(r'blood urea nitrogen', re.IGNORECASE): 'Blood Urea Nitrogen (BUN)',\n",
        "    re.compile(r'bun', re.IGNORECASE): 'Blood Urea Nitrogen (BUN)',\n",
        "    re.compile(r'creatinine', re.IGNORECASE): 'Creatinine',\n",
        "    re.compile(r'uric acid', re.IGNORECASE): 'Uric Acid',\n",
        "    # Lipids\n",
        "    re.compile(r'total cholesterol', re.IGNORECASE): 'Cholesterol - Total',\n",
        "    re.compile(r'triglycerides', re.IGNORECASE): 'Triglycerides',\n",
        "    re.compile(r'hdl cholesterol', re.IGNORECASE): 'HDL Cholesterol',\n",
        "    re.compile(r'ldl cholesterol', re.IGNORECASE): 'LDL Cholesterol',\n",
        "    re.compile(r'vldl cholesterol', re.IGNORECASE): 'VLDL Cholesterol',\n",
        "    re.compile(r'cholesterol/hdl ratio', re.IGNORECASE): 'Total Cholesterol/HDL Ratio',\n",
        "    # Diabetes\n",
        "    re.compile(r'glucose fasting', re.IGNORECASE): 'Glucose - Fasting',\n",
        "    re.compile(r'fbs', re.IGNORECASE): 'Glucose - Fasting',\n",
        "    re.compile(r'glucose random', re.IGNORECASE): 'Glucose - Random',\n",
        "    re.compile(r'rbs', re.IGNORECASE): 'Glucose - Random',\n",
        "    re.compile(r'hba1c', re.IGNORECASE): 'Glycated Haemoglobin (HbA1c)',\n",
        "    # Thyroid\n",
        "    re.compile(r'tsh', re.IGNORECASE): 'Thyroid Stimulating Hormone (TSH)',\n",
        "    re.compile(r'total t3', re.IGNORECASE): 'Total T3',\n",
        "    re.compile(r'total t4', re.IGNORECASE): 'Total T4',\n",
        "    re.compile(r'free t3', re.IGNORECASE): 'Free T3 (FT3)',\n",
        "    re.compile(r'ft3', re.IGNORECASE): 'Free T3 (FT3)',\n",
        "    re.compile(r'free t4', re.IGNORECASE): 'Free T4 (FT4)',\n",
        "    re.compile(r'ft4', re.IGNORECASE): 'Free T4 (FT4)',\n",
        "}\n",
        "\n",
        "UNIT_MAPPING = {\n",
        "    re.compile(r'gm/dl', re.IGNORECASE): 'g/dL',\n",
        "    re.compile(r'g/l', re.IGNORECASE): 'g/L',\n",
        "    re.compile(r'cells/cumm', re.IGNORECASE): 'cells/µL',\n",
        "    re.compile(r'/cumm', re.IGNORECASE): '/µL',\n",
        "    re.compile(r'thou/cumm', re.IGNORECASE): 'x10³/µL',\n",
        "    re.compile(r'10\\^3/ul', re.IGNORECASE): 'x10³/µL',\n",
        "    re.compile(r'x10\\^3/μl', re.IGNORECASE): 'x10³/µL',\n",
        "    re.compile(r'mill/cumm', re.IGNORECASE): 'x10⁶/µL',\n",
        "    re.compile(r'10\\^6/ul', re.IGNORECASE): 'x10⁶/µL',\n",
        "    re.compile(r'x10\\^6/μl', re.IGNORECASE): 'x10⁶/µL',\n",
        "    re.compile(r'mg/dl', re.IGNORECASE): 'mg/dL',\n",
        "    re.compile(r'iu/l', re.IGNORECASE): 'IU/L',\n",
        "    re.compile(r'u/l', re.IGNORECASE): 'U/L', # Common variation for IU/L\n",
        "    re.compile(r'µiu/ml', re.IGNORECASE): 'µIU/mL', # For TSH etc.\n",
        "    re.compile(r'ng/dl', re.IGNORECASE): 'ng/dL', # For some hormones\n",
        "    re.compile(r'pg/ml', re.IGNORECASE): 'pg/mL', # For FT3 etc.\n",
        "    re.compile(r'%', re.IGNORECASE): '%', # Percentage\n",
        "    re.compile(r'fl', re.IGNORECASE): 'fL', # Femtoliters for MCV\n",
        "    re.compile(r'pg', re.IGNORECASE): 'pg', # Picograms for MCH\n",
        "    re.compile(r'mm/hr', re.IGNORECASE): 'mm/hr', # For ESR\n",
        "}\n",
        "\n",
        "STATUS_MAPPING = {\n",
        "    re.compile(r'low', re.IGNORECASE): 'Low',\n",
        "    re.compile(r'normal', re.IGNORECASE): 'Normal',\n",
        "    re.compile(r'high', re.IGNORECASE): 'High',\n",
        "    re.compile(r'critical', re.IGNORECASE): 'Critical',\n",
        "    re.compile(r'n/a', re.IGNORECASE): 'N/A',\n",
        "    re.compile(r'not applicable', re.IGNORECASE): 'N/A',\n",
        "    re.compile(r'within normal limits', re.IGNORECASE): 'Normal',\n",
        "    re.compile(r'within reference range', re.IGNORECASE): 'Normal',\n",
        "    re.compile(r'near optimal', re.IGNORECASE): 'Near Optimal', # From user's example output\n",
        "    re.compile(r'desirable', re.IGNORECASE): 'Desirable',\n",
        "    re.compile(r'borderline high', re.IGNORECASE): 'Borderline High',\n",
        "}"
      ],
      "metadata": {
        "id": "5KwYa4sEnpdl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_value(value, mapping_dict, default_case='title'):\n",
        "    \"\"\"Applies mapping and case standardization to a value.\"\"\"\n",
        "    if not isinstance(value, str):\n",
        "        return value # Return as is if not a string\n",
        "\n",
        "    original_value = value.strip()\n",
        "    standardized_value = original_value\n",
        "\n",
        "    for pattern, standard_form in mapping_dict.items():\n",
        "        if pattern.search(original_value):\n",
        "            standardized_value = standard_form\n",
        "            break # Apply first match\n",
        "\n",
        "    # Apply case standardization if no mapping was applied or if mapped value needs it\n",
        "    if default_case == 'title':\n",
        "        return standardized_value.title() if standardized_value else standardized_value\n",
        "    elif default_case == 'original': # Used for units where case matters (e.g. g/dL)\n",
        "        return standardized_value\n",
        "    elif default_case == 'lower':\n",
        "        return standardized_value.lower() if standardized_value else standardized_value\n",
        "    return standardized_value"
      ],
      "metadata": {
        "id": "JKsGPVCCnpge"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting drive: {e}\")\n",
        "\n",
        "# Configure Gemini API\n",
        "try:\n",
        "    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "    genai.configure(api_key=GEMINI_API_KEY)\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "    print(\"Gemini API configured successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Please add your Gemini API key to Colab secrets with name 'GEMINI_API_KEY'. Error: {e}\")\n",
        "    model = None\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    \"\"\"Extract text from PDF file\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'rb') as file:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in pdf_reader.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text\n",
        "        if not text.strip():\n",
        "            print(f\"Warning: No text extracted from {os.path.basename(file_path)}. PDF might be image-based or empty.\")\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading PDF {file_path}: {str(e)}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTezuYCqnw4z",
        "outputId": "e129d3b1-d4b4-4b93-d0bc-d09163a57cda"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Gemini API configured successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_medical_report(text):\n",
        "    \"\"\"Use API to analyze medical report and extract structured data\"\"\"\n",
        "    if not model:\n",
        "        print(\"Gemini model not initialized. Cannot analyze report.\")\n",
        "        return None\n",
        "    if not text or not text.strip():\n",
        "        print(\"No text provided to analyze.\")\n",
        "        return None\n",
        "\n",
        "    # Enhanced prompt for better date and patient info extraction\n",
        "    prompt = \"\"\"\n",
        "    Analyze this medical test report. Extract all patient information and test results.\n",
        "    The patient's full name is critical. Also extract Patient ID, Age, and Gender.\n",
        "    The report date or collection date is also critical. Ensure date is in<y_bin_358>-MM-DD format if possible.\n",
        "\n",
        "    For each test parameter, extract:\n",
        "    - Test Name (e.g., \"Haemoglobin\", \"Total Leucocyte Count\")\n",
        "    - Result (numerical value or finding like \"Detected\", \"Not Detected\")\n",
        "    - Unit of measurement (e.g., \"g/dL\", \"cells/µL\")\n",
        "    - Reference Range (e.g., \"13.0 - 17.0\")\n",
        "    - Status (interpret as \"Low\", \"Normal\", \"High\", \"Critical\", or \"N/A\" if not applicable or clearly stated)\n",
        "    - Category (e.g., \"Haematology\", \"Liver Function Test\")\n",
        "\n",
        "    Return the data in this exact JSON format:\n",
        "    {\n",
        "        \"patient_info\": {\n",
        "            \"name\": \"Full Patient Name\",\n",
        "            \"age\": \"Age (e.g., 35 years, 35 Y)\",\n",
        "            \"gender\": \"Gender (e.g., Male, Female)\",\n",
        "            \"patient_id\": \"Patient ID or Registration No.\",\n",
        "            \"date\": \"Test Date or Report Date (YYYY-MM-DD)\"\n",
        "        },\n",
        "        \"test_results\": [\n",
        "            {\n",
        "                \"test_name\": \"Name of the test\",\n",
        "                \"result\": \"Numerical value or finding\",\n",
        "                \"unit\": \"Unit of measurement\",\n",
        "                \"reference_range\": \"Normal reference range\",\n",
        "                \"status\": \"Low/Normal/High/Critical/N/A\",\n",
        "                \"category\": \"Test category\"\n",
        "            }\n",
        "        ],\n",
        "        \"abnormal_findings\": [\n",
        "            \"List any general abnormal findings or summary remarks from the report, if present.\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    Medical Report Text:\n",
        "    \"\"\" + text\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        response_text = response.text\n",
        "        match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
        "        if match:\n",
        "            json_str = match.group(0)\n",
        "            try:\n",
        "                return json.loads(json_str)\n",
        "            except json.JSONDecodeError as json_e:\n",
        "                print(f\"Error decoding JSON from response: {json_e}\")\n",
        "                print(f\"Problematic JSON string (first 500 chars): {json_str[:500]}\")\n",
        "                return None\n",
        "        else:\n",
        "            print(\"Could not find valid JSON in API response.\")\n",
        "            print(f\"API Response text (first 500 chars): {response_text[:500]}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error analyzing report with Gemini: {str(e)}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "dmDA5IiVnw7t"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_drive_folder(folder_path):\n",
        "    \"\"\"Process all PDF files in the specified Google Drive folder\"\"\"\n",
        "    all_results_from_ai = []\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"Folder not found: {folder_path}\")\n",
        "        return None\n",
        "    pdf_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.pdf')]\n",
        "    if not pdf_files:\n",
        "        print(f\"No PDF files found in the folder: {folder_path}\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Found {len(pdf_files)} PDF files to process in {folder_path}...\")\n",
        "    for i, filename in enumerate(pdf_files, 1):\n",
        "        print(f\"\\nProcessing file {i}/{len(pdf_files)}: {filename}\")\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        text = extract_text_from_pdf(file_path)\n",
        "        if not text:\n",
        "            print(f\"Could not extract text from {filename}, skipping analysis.\")\n",
        "            continue\n",
        "        analysis = analyze_medical_report(text)\n",
        "        if not analysis:\n",
        "            print(f\"Could not analyze {filename}, skipping.\")\n",
        "            continue\n",
        "        analysis['source_filename'] = filename # Add source filename for traceability\n",
        "        all_results_from_ai.append(analysis)\n",
        "        print(f\"✓ Successfully processed and analyzed {filename}\")\n",
        "    return all_results_from_ai"
      ],
      "metadata": {
        "id": "9PY7iZbqnw-s"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cleaned_single_csv(all_ai_results, output_filename='cleaned_medical_reports_analysis.csv'):\n",
        "    \"\"\"\n",
        "    Creates a single, cleaned CSV file in long format from all AI analysis results.\n",
        "    Includes both the original and standardized Test_Name.\n",
        "    The DataFrame is sorted by Test_Category, then Test_Name.\n",
        "    \"\"\"\n",
        "    if not all_ai_results:\n",
        "        print(\"No AI results to process for CSV creation.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    all_rows_for_csv = []\n",
        "\n",
        "    for report_json in all_ai_results:\n",
        "        patient_info = report_json.get('patient_info', {})\n",
        "        source_file = report_json.get('source_filename', 'N/A')\n",
        "\n",
        "        patient_id = patient_info.get('patient_id', 'N/A')\n",
        "        age = patient_info.get('age', 'N/A')\n",
        "        gender = patient_info.get('gender', 'N/A')\n",
        "        test_date = patient_info.get('date', 'N/A')\n",
        "\n",
        "        for test_result in report_json.get('test_results', []):\n",
        "            raw_test_name = test_result.get('test_name', 'UnknownTest') # Get the original name\n",
        "            raw_unit = test_result.get('unit', '')\n",
        "            raw_status = test_result.get('status', '')\n",
        "\n",
        "            std_test_name = standardize_value(raw_test_name, TEST_NAME_MAPPING, default_case='title')\n",
        "            std_unit = standardize_value(raw_unit, UNIT_MAPPING, default_case='original')\n",
        "            std_status = standardize_value(raw_status, STATUS_MAPPING, default_case='title')\n",
        "\n",
        "            row = {\n",
        "                'Source_Filename': source_file,\n",
        "                'Patient_ID': patient_id,\n",
        "                'Age': age,\n",
        "                'Gender': gender,\n",
        "                'Test_Date': test_date,\n",
        "                'Test_Category': test_result.get('category', 'N/A'),\n",
        "                'Original_Test_Name': raw_test_name,  # Add the original test name here\n",
        "                'Test_Name': std_test_name,\n",
        "                'Result': test_result.get('result', ''),\n",
        "                'Unit': std_unit,\n",
        "                'Reference_Range': test_result.get('reference_range', ''),\n",
        "                'Status': std_status,\n",
        "                'Processed_Date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "            }\n",
        "            all_rows_for_csv.append(row)\n",
        "\n",
        "    if not all_rows_for_csv:\n",
        "        print(\"No data rows were generated for the CSV.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    df = pd.DataFrame(all_rows_for_csv)\n",
        "\n",
        "    # Update column_order to include 'Original_Test_Name'\n",
        "    column_order = [\n",
        "        'Source_Filename', 'Patient_ID', 'Age', 'Gender', 'Test_Date',\n",
        "        'Test_Category', 'Original_Test_Name', 'Test_Name', 'Result', 'Unit', 'Reference_Range', 'Status',\n",
        "        'Processed_Date'\n",
        "    ]\n",
        "    final_columns = [col for col in column_order if col in df.columns]\n",
        "    df = df[final_columns] # Reorder columns to the desired order\n",
        "\n",
        "    # Sort the DataFrame\n",
        "    sort_by_keys = []\n",
        "\n",
        "    if 'Test_Name' in df.columns:\n",
        "        sort_by_keys.append('Test_Name')\n",
        "\n",
        "    if 'Test_Date' in df.columns: # For consistent ordering within Test_Name\n",
        "        sort_by_keys.append('Test_Date')\n",
        "\n",
        "    if 'Test_Category' in df.columns:\n",
        "        sort_by_keys.append('Test_Category')\n",
        "\n",
        "\n",
        "    if 'Patient_ID' in df.columns: # Further tie-breaker\n",
        "        sort_by_keys.append('Patient_ID')\n",
        "\n",
        "    if sort_by_keys: # Ensure there's at least one valid key to sort by\n",
        "        df = df.sort_values(by=sort_by_keys).reset_index(drop=True)\n",
        "    else:\n",
        "        print(\"Warning: Could not sort DataFrame as necessary columns are missing.\")\n",
        "\n",
        "\n",
        "    try:\n",
        "        df.to_csv(output_filename, index=False)\n",
        "        print(f\"\\n✓ Cleaned single CSV file saved as: {output_filename}\")\n",
        "        print(f\"  Total records (test entries): {len(df)}\")\n",
        "        if not df.empty:\n",
        "            print(f\"  Unique standardized test names found: {df['Test_Name'].nunique()}\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving CSV file {output_filename}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qjH-zLtsnpjj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Main execution ---\n",
        "def main():\n",
        "    \"\"\"Main function to process medical reports and generate a single cleaned CSV.\"\"\"\n",
        "    if not model:\n",
        "        print(\"Terminating main function as Gemini model is not initialized.\")\n",
        "        return\n",
        "\n",
        "    FOLDER_PATH = input(\"Enter the path to your Google Drive folder containing PDF reports (e.g., /content/drive/MyDrive/Medical_Reports): \")\n",
        "\n",
        "    print(\"\\nStarting medical report analysis...\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    all_extracted_data_from_pdfs = process_drive_folder(FOLDER_PATH)\n",
        "\n",
        "    if not all_extracted_data_from_pdfs:\n",
        "        print(\"No data was successfully extracted from any PDF files. Exiting.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n✓ Successfully processed {len(all_extracted_data_from_pdfs)} PDF file(s) and extracted raw data structures.\")\n",
        "\n",
        "    print(\"\\n--- Generating Single Cleaned CSV File ---\")\n",
        "    final_df = create_cleaned_single_csv(all_extracted_data_from_pdfs)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"ANALYSIS COMPLETE!\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    if final_df.empty:\n",
        "        print(\"No CSV file was generated or the generated file was empty.\")\n",
        "    else:\n",
        "        print(f\"A single cleaned CSV has been generated: '{'cleaned_medical_reports_analysis.csv'}'\")\n",
        "        print(f\"  It contains {len(final_df)} test entries.\")\n",
        "\n",
        "    output_csv_name = 'cleaned_medical_reports_analysis.csv'\n",
        "    if not final_df.empty and os.path.exists(output_csv_name):\n",
        "        download_choice = input(f\"\\nDo you want to download the '{output_csv_name}' file? (y/n): \").lower()\n",
        "        if download_choice == 'y':\n",
        "            files.download(output_csv_name)\n",
        "            print(f\"Downloading {output_csv_name}...\")\n",
        "    elif not final_df.empty:\n",
        "        print(f\"Warning: CSV file {output_csv_name} was processed but not found on disk for download.\")\n",
        "\n",
        "    print(\"\\nProcessing finished. The CSV file is saved in the Colab environment.\")\n",
        "    print(f\"You can find it in the directory: {os.getcwd()}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if model:\n",
        "        main()\n",
        "    else:\n",
        "        print(\"Main function not executed because Gemini model initialization failed. Please check your API key setup.\")\n",
        "\n",
        "print(\"\\nScript setup complete.\")\n",
        "print(\"If the Gemini API is configured, you can run the `main()` function cell to start processing.\")\n",
        "print(\"Instructions:\")\n",
        "print(\"1. Ensure your Gemini API key is added to Colab secrets (View -> Secrets -> Add new secret 'GEMINI_API_KEY').\")\n",
        "print(\"2. Upload your PDF medical reports to a folder in your Google Drive.\")\n",
        "print(\"3. When prompted by `main()`, enter the full path to that Google Drive folder.\")\n",
        "print(\"4. The script will process the PDFs and generate a single, cleaned CSV file named 'cleaned_medical_reports_analysis.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "id": "iyJiK3Cenpmc",
        "outputId": "76ac8b7a-490f-4ce0-fc09-7e9792897e8b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the path to your Google Drive folder containing PDF reports (e.g., /content/drive/MyDrive/Medical_Reports): /content/drive/MyDrive/Tests/Test Reports/Parmaansh\n",
            "\n",
            "Starting medical report analysis...\n",
            "==================================================\n",
            "Found 1 PDF files to process in /content/drive/MyDrive/Tests/Test Reports/Parmaansh...\n",
            "\n",
            "Processing file 1/1: 30403605847.pdf\n",
            "✓ Successfully processed and analyzed 30403605847.pdf\n",
            "\n",
            "✓ Successfully processed 1 PDF file(s) and extracted raw data structures.\n",
            "\n",
            "--- Generating Single Cleaned CSV File ---\n",
            "\n",
            "✓ Cleaned single CSV file saved as: cleaned_medical_reports_analysis.csv\n",
            "  Total records (test entries): 76\n",
            "  Unique standardized test names found: 65\n",
            "\n",
            "==================================================\n",
            "ANALYSIS COMPLETE!\n",
            "==================================================\n",
            "A single cleaned CSV has been generated: 'cleaned_medical_reports_analysis.csv'\n",
            "  It contains 76 test entries.\n",
            "\n",
            "Do you want to download the 'cleaned_medical_reports_analysis.csv' file? (y/n): y\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7685126a-9a18-4512-93a5-d3ee57301604\", \"cleaned_medical_reports_analysis.csv\", 10912)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading cleaned_medical_reports_analysis.csv...\n",
            "\n",
            "Processing finished. The CSV file is saved in the Colab environment.\n",
            "You can find it in the directory: /content\n",
            "\n",
            "Script setup complete.\n",
            "If the Gemini API is configured, you can run the `main()` function cell to start processing.\n",
            "Instructions:\n",
            "1. Ensure your Gemini API key is added to Colab secrets (View -> Secrets -> Add new secret 'GEMINI_API_KEY').\n",
            "2. Upload your PDF medical reports to a folder in your Google Drive.\n",
            "3. When prompted by `main()`, enter the full path to that Google Drive folder.\n",
            "4. The script will process the PDFs and generate a single, cleaned CSV file named 'cleaned_medical_reports_analysis.csv'.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}